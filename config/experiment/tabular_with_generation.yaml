# @package _global_
defaults:
  - /model: llama3.1-8b-instruct
  - _self_
  - /task: adult_causal
  - /prompt: zero_shot

training:
  bf16: false
  world_size: 2
  per_device_batch_size: 16
  gradient_accumulation_steps: 4

do_train: false
do_eval: true
do_test: false

# python run.py experiment=tabular_with_generation
# python run.py -m experiment=tabular_with_generation model=llama3-8b do_eval=true do_test=false # LastTokenModel을 써야 됌
