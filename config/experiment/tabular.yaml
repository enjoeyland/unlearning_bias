# @package _global_
defaults:
  - _self_
  - /task: adult_filter
  - /method: finetune  # options: [original, negtaskvector_tabular, finetune]
  - /model: opt-1.3b

training:  
  use_lora: true
  world_size: 2
  per_device_batch_size: 16
  gradient_accumulation_steps: 1

# training.per_device_batch_size=32 training.gradient_accumulation_steps=4

callbacks:
  eval_steps: 1.0
  max_tolerance: 3
  early_stop_step: null

# method:
#   fit_target: forget  # options: [forget, retain]

do_train: true
do_eval: false
do_test: false

# python run.py -m method.fit_target=retain,forget