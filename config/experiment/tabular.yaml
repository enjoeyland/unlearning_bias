# @package _global_
defaults:
  - _self_
  - /task: adult_filter
  - /method: finetune  # options: [original, negtaskvector_tabular, finetune]
  - /model: opt-1.3b

training:  
  # use_lora: true
  use_lora: false
  world_size: 1
  per_device_batch_size: 32
  gradient_accumulation_steps: 1
  dp_strategy: ddp  # options: [auto, ddp, ddp_find_unused_parameters_true, deepspeed, deepspeed_stage_1, deepspeed_stage_2, deepspeed_stage_2_offload, deepspeed_stage_3, deepspeed_stage_3_offload]

callbacks:
  eval_steps: 1.0
  max_tolerance: 3
  early_stop_step: null

# method:
#   fit_target: forget  # options: [forget, retain]

do_train: true
do_eval: false
do_test: false

# python run.py -m method.fit_target=retain,forget