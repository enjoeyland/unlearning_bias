# @package _global_
defaults:
  - _self_
  - /task: adult_filter
  - /method: finetune  # options: [original, negtaskvector_tabular, finetune]
  - /model: opt-1.3b_without_lora

training:  
  # use_lora: true
  use_lora: false
  world_size: 1
  per_device_batch_size: 32
  gradient_accumulation_steps: 1

callbacks:
  eval_steps: 1.0
  max_tolerance: 3
  early_stop_step: null

# method:
#   fit_target: forget  # options: [forget, retain]

do_train: true
do_eval: false
do_test: false

# python run.py -m experiment=tabular_without_lora method.fit_target=retain,forget