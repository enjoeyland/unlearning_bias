# @package _global_
method:
  name : forget_finetune # forget_tv로 뺀 모델을 retain으로 학습
  fit_target: retain  # options: [forget, retain]
  run_name: BS${training.train_batch_size}_LR${training.learning_rate}_S${training.seed}
  forget_scaling_coef: 1
  retain_scaling_coef: 0
  load_dir:
    forget: .checkpoints/${model.name}/${task.name}/finetune/${method.run_name}_forget
    retain: null
  load_ckpts:
    forget: null
    retain: null
  save_model: false
  normalize: false

  metric: spd
  mode: max

training:
  world_size: 2
  per_device_batch_size: 16
  gradient_accumulation_steps: 1
# python run.py method=forget_finetune