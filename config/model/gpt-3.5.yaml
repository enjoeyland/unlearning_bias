# @package _global_
model:
    name: gpt-3.5
    hf: gpt-3.5-turbo
    type: decoder
    learning_rate: none

training:
    world_size: 1
    per_device_batch_size: 8
  
# python run.py -m experiment=tabular_with_generation model=gpt-3.5